{
    "name": "root",
    "gauges": {
        "Crawler.Policy.Entropy.mean": {
            "value": 0.6267575025558472,
            "min": 0.597064197063446,
            "max": 1.279964566230774,
            "count": 48
        },
        "Crawler.Policy.Entropy.sum": {
            "value": 18605.296875,
            "min": 18282.10546875,
            "max": 38916.04296875,
            "count": 48
        },
        "Crawler.Environment.EpisodeLength.mean": {
            "value": 872.0882352941177,
            "min": 64.24463519313305,
            "max": 934.90625,
            "count": 48
        },
        "Crawler.Environment.EpisodeLength.sum": {
            "value": 29651.0,
            "min": 29312.0,
            "max": 30684.0,
            "count": 48
        },
        "Crawler.Step.mean": {
            "value": 1439647.0,
            "min": 29404.0,
            "max": 1439647.0,
            "count": 48
        },
        "Crawler.Step.sum": {
            "value": 1439647.0,
            "min": 29404.0,
            "max": 1439647.0,
            "count": 48
        },
        "Crawler.Policy.ExtrinsicValue.mean": {
            "value": 390.200439453125,
            "min": 20.142850875854492,
            "max": 545.5875244140625,
            "count": 48
        },
        "Crawler.Policy.ExtrinsicValue.sum": {
            "value": 13266.814453125,
            "min": 3605.992919921875,
            "max": 78451.046875,
            "count": 48
        },
        "Crawler.Environment.CumulativeReward.mean": {
            "value": 63.157007219160306,
            "min": 6.457825544373742,
            "max": 2143.301735583647,
            "count": 48
        },
        "Crawler.Environment.CumulativeReward.sum": {
            "value": 2147.3382454514503,
            "min": 936.3847039341927,
            "max": 307851.6622822881,
            "count": 48
        },
        "Crawler.Policy.ExtrinsicReward.mean": {
            "value": 63.157007219160306,
            "min": 6.457825544373742,
            "max": 2143.301735583647,
            "count": 48
        },
        "Crawler.Policy.ExtrinsicReward.sum": {
            "value": 2147.3382454514503,
            "min": 936.3847039341927,
            "max": 307851.6622822881,
            "count": 48
        },
        "Crawler.Losses.PolicyLoss.mean": {
            "value": -373.46004849890335,
            "min": -523.9590251867168,
            "max": -44.05529176723698,
            "count": 48
        },
        "Crawler.Losses.PolicyLoss.sum": {
            "value": -554214.7119723726,
            "min": -787383.1666556692,
            "max": -64761.27889783836,
            "count": 48
        },
        "Crawler.Losses.ValueLoss.mean": {
            "value": 12.791631047685987,
            "min": 6.305725072650577,
            "max": 217.80665750264114,
            "count": 48
        },
        "Crawler.Losses.ValueLoss.sum": {
            "value": 18982.780474766005,
            "min": 9269.415856796348,
            "max": 327145.599568967,
            "count": 48
        },
        "Crawler.Losses.Q1Loss.mean": {
            "value": 15.643557427962508,
            "min": 15.356741153942336,
            "max": 819.5083272396914,
            "count": 48
        },
        "Crawler.Losses.Q1Loss.sum": {
            "value": 23215.039223096363,
            "min": 22574.409496295233,
            "max": 1247291.6740588103,
            "count": 48
        },
        "Crawler.Losses.Q2Loss.mean": {
            "value": 17.048272166816368,
            "min": 15.321839000051364,
            "max": 819.2614215999384,
            "count": 48
        },
        "Crawler.Losses.Q2Loss.sum": {
            "value": 25299.63589555549,
            "min": 22523.103330075504,
            "max": 1246915.8836751063,
            "count": 48
        },
        "Crawler.Policy.ContinuousEntropyCoeff.mean": {
            "value": 0.02154379574922527,
            "min": 0.02154379574922527,
            "max": 0.8119299721200726,
            "count": 48
        },
        "Crawler.Policy.ContinuousEntropyCoeff.sum": {
            "value": 31.9709928918503,
            "min": 31.9709928918503,
            "max": 1193.5370590165066,
            "count": 48
        },
        "Crawler.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0002999999999999999,
            "max": 0.0003,
            "count": 48
        },
        "Crawler.Policy.LearningRate.sum": {
            "value": 0.44519999999999993,
            "min": 0.43649999999999994,
            "max": 0.46079999999999993,
            "count": 48
        },
        "Crawler.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        },
        "Crawler.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        },
        "Attacker.Policy.Entropy.mean": {
            "value": 0.7846301794052124,
            "min": -0.8924342393875122,
            "max": 2.653954029083252,
            "count": 48
        },
        "Attacker.Policy.Entropy.sum": {
            "value": 23538.90625,
            "min": -26781.951171875,
            "max": 80015.703125,
            "count": 48
        },
        "Attacker.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 14.291836734693877,
            "max": 999.0,
            "count": 48
        },
        "Attacker.Environment.EpisodeLength.sum": {
            "value": 29970.0,
            "min": 28012.0,
            "max": 30764.0,
            "count": 48
        },
        "Attacker.Step.mean": {
            "value": 1439257.0,
            "min": 29410.0,
            "max": 1439257.0,
            "count": 48
        },
        "Attacker.Step.sum": {
            "value": 1439257.0,
            "min": 29410.0,
            "max": 1439257.0,
            "count": 48
        },
        "Attacker.Policy.ExtrinsicValue.mean": {
            "value": -1.4771214723587036,
            "min": -16.606422424316406,
            "max": -0.6256119608879089,
            "count": 48
        },
        "Attacker.Policy.ExtrinsicValue.sum": {
            "value": -44.31364440917969,
            "min": -31125.021484375,
            "max": -18.787492752075195,
            "count": 48
        },
        "Attacker.Environment.CumulativeReward.mean": {
            "value": -33.96666666666667,
            "min": -116.8,
            "max": -1.9653061224489796,
            "count": 48
        },
        "Attacker.Environment.CumulativeReward.sum": {
            "value": -1019.0,
            "min": -5877.0,
            "max": -91.0,
            "count": 48
        },
        "Attacker.Policy.ExtrinsicReward.mean": {
            "value": -33.96666666666667,
            "min": -116.8,
            "max": -1.9653061224489796,
            "count": 48
        },
        "Attacker.Policy.ExtrinsicReward.sum": {
            "value": -1019.0,
            "min": -5877.0,
            "max": -91.0,
            "count": 48
        },
        "Attacker.Losses.PolicyLoss.mean": {
            "value": 5.933814591200209,
            "min": 2.5469282338308035,
            "max": 75.50872407200151,
            "count": 48
        },
        "Attacker.Losses.PolicyLoss.sum": {
            "value": 8900.721886800313,
            "min": 3798.455993936647,
            "max": 113414.10355614628,
            "count": 48
        },
        "Attacker.Losses.ValueLoss.mean": {
            "value": 0.00016329285979977773,
            "min": 0.0001203666586778268,
            "max": 0.04298981136670032,
            "count": 48
        },
        "Attacker.Losses.ValueLoss.sum": {
            "value": 0.24493928969966658,
            "min": 0.17994815472335107,
            "max": 64.57069667278388,
            "count": 48
        },
        "Attacker.Losses.Q1Loss.mean": {
            "value": 0.015832991375721858,
            "min": 0.015502040365369297,
            "max": 2.1990520133886173,
            "count": 48
        },
        "Attacker.Losses.Q1Loss.sum": {
            "value": 23.749487063582784,
            "min": 23.253060548053945,
            "max": 3298.578020082926,
            "count": 48
        },
        "Attacker.Losses.Q2Loss.mean": {
            "value": 0.015835161802601742,
            "min": 0.01550373844343378,
            "max": 2.198024606839497,
            "count": 48
        },
        "Attacker.Losses.Q2Loss.sum": {
            "value": 23.752742703902612,
            "min": 23.25560766515067,
            "max": 3297.036910259246,
            "count": 48
        },
        "Attacker.Policy.DiscreteEntropyCoeff.mean": {
            "value": 0.10192790846116846,
            "min": 0.033184595117256306,
            "max": 0.8109575977851359,
            "count": 48
        },
        "Attacker.Policy.DiscreteEntropyCoeff.sum": {
            "value": 152.8918626917527,
            "min": 50.17510781729154,
            "max": 1192.1076687441498,
            "count": 48
        },
        "Attacker.Policy.ContinuousEntropyCoeff.mean": {
            "value": 0.0011433491801041639,
            "min": 0.0011433491801041639,
            "max": 0.810621503157607,
            "count": 48
        },
        "Attacker.Policy.ContinuousEntropyCoeff.sum": {
            "value": 1.7150237701562459,
            "min": 1.7150237701562459,
            "max": 1191.6136096416822,
            "count": 48
        },
        "Attacker.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0002999999999999999,
            "max": 0.0003,
            "count": 48
        },
        "Attacker.Policy.LearningRate.sum": {
            "value": 0.44999999999999996,
            "min": 0.43679999999999997,
            "max": 0.46199999999999997,
            "count": 48
        },
        "Attacker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        },
        "Attacker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 48
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1684929663",
        "python_version": "3.9.0 (default, Nov 15 2020, 14:28:56) \n[GCC 7.3.0]",
        "command_line_arguments": "/home/kds/anaconda3/envs/mapa/bin/mlagents-learn config/sac/Crawler.yaml --env Build/CrawlerAttack/CrawlerAttack.x86_64 --run-id CSA_0 --no-graphics --base-port 5008 --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0+cu115",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1684958664"
    },
    "total": 29001.105035925022,
    "count": 1,
    "self": 0.007966364035382867,
    "children": {
        "run_training.setup": {
            "total": 0.01178718899609521,
            "count": 1,
            "self": 0.01178718899609521
        },
        "TrainerController.start_learning": {
            "total": 29001.08528237199,
            "count": 1,
            "self": 32.059686718683224,
            "children": {
                "TrainerController._reset_env": {
                    "total": 3.7200416660052724,
                    "count": 1,
                    "self": 3.7200416660052724
                },
                "TrainerController.advance": {
                    "total": 28964.841384237283,
                    "count": 1482257,
                    "self": 33.88150715015945,
                    "children": {
                        "env_step": {
                            "total": 20187.680003804795,
                            "count": 1482257,
                            "self": 12337.113343241159,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 7830.431838176912,
                                    "count": 1482257,
                                    "self": 179.2679935171036,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 7651.163844659808,
                                            "count": 2920892,
                                            "self": 7651.163844659808
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 20.13482238672441,
                                    "count": 1482256,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 28906.15697763351,
                                            "count": 1482256,
                                            "is_parallel": true,
                                            "self": 18855.667427022127,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0024021890421863645,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0011264640488661826,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.001275724993320182,
                                                                    "count": 6,
                                                                    "is_parallel": true,
                                                                    "self": 0.001275724993320182
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.03733521900721826,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0002998520212713629,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.00036636798176914454,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.00036636798176914454
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.0353502270008903,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.0353502270008903
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.0013187720032874495,
                                                                    "count": 2,
                                                                    "is_parallel": true,
                                                                    "self": 0.0007376909779850394,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.0005810810253024101,
                                                                            "count": 6,
                                                                            "is_parallel": true,
                                                                            "self": 0.0005810810253024101
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 10050.489550611383,
                                                    "count": 1482255,
                                                    "is_parallel": true,
                                                    "self": 369.23965298896655,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 328.85762118481216,
                                                            "count": 1482255,
                                                            "is_parallel": true,
                                                            "self": 328.85762118481216
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 7712.632641530014,
                                                            "count": 1482255,
                                                            "is_parallel": true,
                                                            "self": 7712.632641530014
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1639.7596349075902,
                                                            "count": 2964510,
                                                            "is_parallel": true,
                                                            "self": 929.8857570796972,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 709.873877827893,
                                                                    "count": 8893530,
                                                                    "is_parallel": true,
                                                                    "self": 709.873877827893
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 8743.279873282328,
                            "count": 2964512,
                            "self": 66.1781868186954,
                            "children": {
                                "process_trajectory": {
                                    "total": 234.7461714539968,
                                    "count": 2964512,
                                    "self": 233.810521367006,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.9356500869907904,
                                            "count": 4,
                                            "self": 0.9356500869907904
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 8442.355515009636,
                                    "count": 2963565,
                                    "self": 14.834484319057083,
                                    "children": {
                                        "OffPolicyTrainer._update_policy": {
                                            "total": 8427.52103069058,
                                            "count": 2963565,
                                            "self": 3848.5683736935607,
                                            "children": {
                                                "TorchSACOptimizer.update": {
                                                    "total": 4578.9526569970185,
                                                    "count": 146019,
                                                    "self": 4578.9526569970185
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.0200019460171461e-06,
                    "count": 1,
                    "self": 1.0200019460171461e-06
                },
                "TrainerController._save_models": {
                    "total": 0.46416873001726344,
                    "count": 1,
                    "self": 0.004208366037346423,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.459960363979917,
                            "count": 2,
                            "self": 0.459960363979917
                        }
                    }
                }
            }
        }
    }
}